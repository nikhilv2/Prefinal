{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9234395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b7bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a16a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading haarcascade_frontalface_default.xml\n",
    "face_model = cv2.CascadeClassifier('../input/haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb064033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    \n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    \n",
    "    # convert to array\n",
    "    pixels = np.asarray(image)\n",
    "    \n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(pixels)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    \n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b53f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face(dir):\n",
    "    faces = list()\n",
    "    paths = list()\n",
    "    \n",
    "    # enumerate files\n",
    "    for filename in os.listdir(dir):\n",
    "        path = dir + filename\n",
    "        face = extract_face(path)\n",
    "        faces.append(face)\n",
    "        paths.append(path)\n",
    "    \n",
    "    return faces, paths\n",
    "\n",
    "def load_dataset(dir):\n",
    "    # list for faces and labels\n",
    "    X, y, paths, t_paths = list(), list(), list(), list()\n",
    "    \n",
    "    for subdir in os.listdir(dir):\n",
    "        path = dir + subdir + '/'\n",
    "        faces, paths = load_face(path)\n",
    "        t_paths = t_paths + paths\n",
    "        labels = [subdir for i in range(len(faces))]\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "        \n",
    "    return np.asarray(X), np.asarray(y), t_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34dd72a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'C:/Users/admin/Prefinal Project/Dataset Prefinal/Training/Kavya/IMG_6680.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6000\\603459297.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load train dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/admin/Prefinal Project/Dataset Prefinal/Training/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6000\\2684651019.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mt_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_paths\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msubdir\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6000\\2684651019.py\u001b[0m in \u001b[0;36mload_face\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpaths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6000\\709815902.py\u001b[0m in \u001b[0;36mextract_face\u001b[1;34m(filename, required_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequired_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m160\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# load image from file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# convert to RGB, if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python37\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3007\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3008\u001b[0m     raise UnidentifiedImageError(\n\u001b[1;32m-> 3009\u001b[1;33m         \u001b[1;34m\"cannot identify image file %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3010\u001b[0m     )\n\u001b[0;32m   3011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'C:/Users/admin/Prefinal Project/Dataset Prefinal/Training/Kavya/IMG_6680.jpg'"
     ]
    }
   ],
   "source": [
    "# load train dataset\n",
    "\n",
    "trainX, trainy, train_paths = load_dataset('C:/Users/admin/Prefinal Project/Dataset Prefinal/Training/')\n",
    "print(trainX.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa000832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "\n",
    "testX, testy, test_paths = load_dataset('C:/Users/admin/Prefinal Project/Dataset Prefinal/Testing/')\n",
    "print(testX.shape, testy.shape, len(test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and compress the dataset for further use\n",
    "np.savez_compressed('new_modified_masked_face.npz', trainX, trainy, testX, testy)\n",
    "print('Done with Compression')\n",
    "#del trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('new_modified_masked_face.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, valid = train_test_split(trainX, test_size=0.4, random_state=42, shuffle=True)\n",
    "del trainX\n",
    "print('Split Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of image in train dataset : %s\" %(len(trainx)))\n",
    "\n",
    "print(\"number of image in train dataset : %s\" %(len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193437dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = train_test_split(trainy, test_size=0.4, random_state=42, shuffle=True)\n",
    "del trainy\n",
    "print('Split Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of image in train dataset : %s\" %(len(y_train)))\n",
    "\n",
    "print(\"number of image in train dataset : %s\" %(len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ba86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and compress the dataset for further use\n",
    "np.savez_compressed('modified_extracted_masked_unmasked.npz', trainx, y_train, valid, y_valid,testX, testy)\n",
    "del trainx, y_train, valid, y_valid, testX, testy\n",
    "print('Done Compressing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('modified_extracted_masked_unmasked.npz')\n",
    "print(data.files)\n",
    "trainx, y_train, valid, y_valid,testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']\n",
    "print('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet_model = load_model('keras-facenet/model/facenet_keras.h5')\n",
    "print('Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577830ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face):\n",
    "    # scale pixel values\n",
    "    face = face.astype('float32')\n",
    "    \n",
    "    # standardization\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face-mean)/std\n",
    "    \n",
    "    # transfer face into one sample (3 dimension to 4 dimension)\n",
    "    sample = np.expand_dims(face, axis=0)\n",
    "    \n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(sample)\n",
    "    \n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ab196",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdTrainX = list()\n",
    "\n",
    "for face in trainx:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTrainX.append(emd)\n",
    "    \n",
    "emdTrainX = np.asarray(emdTrainX)\n",
    "print(emdTrainX.shape)\n",
    "\n",
    "embValid = list()\n",
    "\n",
    "for face in valid:\n",
    "    emd = get_embedding(facenet_model,face)\n",
    "    embValid.append(emd)\n",
    "    \n",
    "embValid = np.asarray(embValid)\n",
    "print(embValid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "emdTestX = list()\n",
    "\n",
    "for face in testX:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTestX.append(emd)\n",
    "    \n",
    "emdTestX = np.asarray(emdTestX)\n",
    "print(emdTestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d853616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save arrays to one file in compressed format\n",
    "np.savez_compressed('embeddings_masked.npz', emdTrainX, y_train, embValid, y_valid, emdTestX, testy)\n",
    "del emdTrainX, y_train, embValid, y_valid, emdTestX, testy\n",
    "print('Here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf05ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('embeddings_masked.npz')\n",
    "print(data.files)\n",
    "emdTrainX, y_train, embValid, y_valid, emdTestX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loaded: ', emdTrainX.shape, y_train.shape, embValid.shape, y_valid.shape, emdTestX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "print(\"Dataset: train=%d,validation = %d, test=%d\" % (emdTrainX.shape[0],embValid.shape[0] ,emdTestX.shape[0]))\n",
    "\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "emdTrainX_norm = in_encoder.transform(emdTrainX)\n",
    "embValid_norm = in_encoder.transform(embValid)\n",
    "emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "encoder_arr = np.append (y_train, 'wangnan')\n",
    "out_encoder.fit(encoder_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy_enc = out_encoder.transform(y_train)\n",
    "y_valid_enc = out_encoder.transform(y_valid)\n",
    "testy_enc = out_encoder.transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36963ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model = model.fit(emdTrainX_norm,trainy_enc)\n",
    "yhat = model.predict(emdTestX_norm)\n",
    "yhat_valid = model.predict(embValid_norm)\n",
    "score_test = accuracy_score(testy_enc, yhat)\n",
    "score_valid = accuracy_score(y_valid_enc, yhat_valid)\n",
    "print('Accuracy: test=%.3f' % (score_test*100))\n",
    "print('Validation accuracy=%.3f' % (score_valid*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model = model.fit(emdTrainX_norm,trainy_enc)\n",
    "yhat = model.predict(emdTestX_norm)\n",
    "score_test = accuracy_score(testy_enc, yhat)\n",
    "print('Accuracy: test=%.3f' % (score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba19866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(emdTrainX_norm, trainy_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "yhat_valid = model.predict(embValid_norm)\n",
    "yhat_test = model.predict(emdTestX_norm)\n",
    "\n",
    "# score\n",
    "score_valid = accuracy_score(y_valid_enc, yhat_valid)\n",
    "score_test = accuracy_score(testy_enc, yhat_test)\n",
    "\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_valid*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa964ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(emdTrainX_norm, trainy_enc)\n",
    "score_test = accuracy_score(testy_enc, yhat_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy: test=%.3f' % (score_test*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 400, random_state = 1)\n",
    "rf.fit(emdTrainX_norm, trainy_enc)\n",
    "score_test = accuracy_score(testy_enc, yhat_test)\n",
    "print('Accuracy: test=%.3f' % (score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "filename = 'linear.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a41128",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('linear.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    # select a random face from test set\n",
    "    selection = choice([i for i in range(testX.shape[0])]) \n",
    "    random_face = testX[selection]\n",
    "    random_face_emd = emdTestX_norm[selection]\n",
    "    random_face_class = testy_enc[selection]\n",
    "    random_face_name = out_encoder.inverse_transform([random_face_class])\n",
    "    \n",
    "    # prediction for the face\n",
    "    samples = np.expand_dims(random_face_emd, axis=0)\n",
    "    yhat_class = loaded_model.predict(samples)\n",
    "    yhat_prob = loaded_model.predict_proba(samples)\n",
    "    class_index = yhat_class[0]\n",
    "    \n",
    "    if class_index <= 10:\n",
    "        # get name\n",
    "        class_probability = yhat_prob[0,class_index] * 100\n",
    "        predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "        \n",
    "        if random_face_name[0] == predict_names[0]:\n",
    "            print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "            print('Expected: %s' % random_face_name[0])\n",
    "            \n",
    "            # plot face\n",
    "            plt.imshow(random_face)\n",
    "            title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "            plt.title(title)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76fb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
